{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# convolutional neural network (CNN) to classify medical X-ray images and detect pneumonia\n",
   "id": "4cdbb10ec96e1ef9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing the libraries\n",
   "id": "a22fcc62dc87010b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:05:49.695973Z",
     "start_time": "2025-02-09T02:05:46.280873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "id": "f244fd4d73e53f49",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 1 - Data Preprocessing\n",
   "id": "9500d14d617b4bb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:05:51.531313Z",
     "start_time": "2025-02-09T02:05:51.528779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TRAINING_SET_DIR = \"/Users/sivaram/Developer/SDS/SuperDataScience-Community-Projects/datasets/chest_xray/train\"\n",
    "TEST_SET_DIR = \"/Users/sivaram/Developer/SDS/SuperDataScience-Community-Projects/datasets/chest_xray/test\"\n",
    "VALIDATION_SET_DIR = \"/Users/sivaram/Developer/SDS/SuperDataScience-Community-Projects/datasets/chest_xray/val\"\n"
   ],
   "id": "363de214f56e60d7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocessing the Training set",
   "id": "109e080f57aca09d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:05:55.456676Z",
     "start_time": "2025-02-09T02:05:55.417285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Image augmentation gives variety and diversity of training set to avoid overfitting\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(TRAINING_SET_DIR,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ],
   "id": "abb0db9cc43e2dab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:05:57.623886Z",
     "start_time": "2025-02-09T02:05:57.621404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = (training_set.class_indices)\n",
    "print(labels)"
   ],
   "id": "95a69a2c7eae5a59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocessing the test set\n",
   "id": "5319d800c00a39a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:05:59.869577Z",
     "start_time": "2025-02-09T02:05:59.858863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = train_datagen.flow_from_directory(TEST_SET_DIR,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ],
   "id": "617bb4fdfce43bd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:01.865460Z",
     "start_time": "2025-02-09T02:06:01.863197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = (test_set.class_indices)\n",
    "print(labels)"
   ],
   "id": "4f93fc226b9ef71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocessing the validation set\n",
   "id": "27dfe9ba12c279b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:04.038609Z",
     "start_time": "2025-02-09T02:06:04.032474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_set = train_datagen.flow_from_directory(VALIDATION_SET_DIR,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ],
   "id": "ff829ecd7f621605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:05.970319Z",
     "start_time": "2025-02-09T02:06:05.967652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = (val_set.class_indices)\n",
    "print(labels)"
   ],
   "id": "c1e7c7d789168fad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 2 - Building the CNN\n",
   "id": "47f844e9686b2d03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialising the CNN",
   "id": "2b0b3c81b9d2fbbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:07.875597Z",
     "start_time": "2025-02-09T02:06:07.867027Z"
    }
   },
   "cell_type": "code",
   "source": "cnn = tf.keras.models.Sequential()\n",
   "id": "11bad8cc58474323",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1 - Convolution",
   "id": "85cd50e384ae2a53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:09.824631Z",
     "start_time": "2025-02-09T02:06:09.778073Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
   "id": "ecb1a694ab2fc7c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sivaram/Developer/SDS/SuperDataScience-Community-Projects/SDS-CP021-pneumonia-detection/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 2 - Pooling",
   "id": "4c686f678fb379b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:11.771341Z",
     "start_time": "2025-02-09T02:06:11.766489Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
   "id": "4b1d58a9f31b66c7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adding a second convolutional layer\n",
   "id": "ff95fb90edea4874"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:13.296635Z",
     "start_time": "2025-02-09T02:06:13.285428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "id": "ebd052c99c55057a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 3 - Flattening",
   "id": "a06c297884bba80a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:15.101838Z",
     "start_time": "2025-02-09T02:06:15.096951Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.add(tf.keras.layers.Flatten())\n",
   "id": "dcbbe4322c03c650",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4 - Full Connection",
   "id": "e36bd901f432469f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:16.933502Z",
     "start_time": "2025-02-09T02:06:16.920937Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
   "id": "b7f6543ca136fb0e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 5 - Output Layer",
   "id": "2d105b9f376d2ceb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:18.121363Z",
     "start_time": "2025-02-09T02:06:18.112052Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
   "id": "650375fc1b5b7c51",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 3 - Training the CNN\n",
   "id": "a55cb537da1cf1a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compiling the CNN",
   "id": "1a690116f3611ee7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:06:20.203846Z",
     "start_time": "2025-02-09T02:06:20.195540Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
   "id": "f7487f26c1293ce0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the CNN on the Training set and evaluating it on the Test set\n",
   "id": "a69c52fc919bb510"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:18:58.545606Z",
     "start_time": "2025-02-09T02:06:21.948924Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)\n",
   "id": "8d0a7b4d4416d3c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sivaram/Developer/SDS/SuperDataScience-Community-Projects/SDS-CP021-pneumonia-detection/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 146ms/step - accuracy: 0.7501 - loss: 0.5198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sivaram/Developer/SDS/SuperDataScience-Community-Projects/SDS-CP021-pneumonia-detection/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 163ms/step - accuracy: 0.7506 - loss: 0.5191 - val_accuracy: 0.7548 - val_loss: 0.5254\n",
      "Epoch 2/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 170ms/step - accuracy: 0.9021 - loss: 0.2329 - val_accuracy: 0.8221 - val_loss: 0.4193\n",
      "Epoch 3/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 178ms/step - accuracy: 0.8995 - loss: 0.2330 - val_accuracy: 0.8237 - val_loss: 0.3983\n",
      "Epoch 4/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 178ms/step - accuracy: 0.9232 - loss: 0.1955 - val_accuracy: 0.7404 - val_loss: 0.8041\n",
      "Epoch 5/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 184ms/step - accuracy: 0.9245 - loss: 0.1848 - val_accuracy: 0.8478 - val_loss: 0.3675\n",
      "Epoch 6/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 185ms/step - accuracy: 0.9195 - loss: 0.1878 - val_accuracy: 0.8542 - val_loss: 0.3498\n",
      "Epoch 7/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 179ms/step - accuracy: 0.9363 - loss: 0.1710 - val_accuracy: 0.8526 - val_loss: 0.3938\n",
      "Epoch 8/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 188ms/step - accuracy: 0.9478 - loss: 0.1373 - val_accuracy: 0.7837 - val_loss: 0.6376\n",
      "Epoch 9/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 191ms/step - accuracy: 0.9396 - loss: 0.1649 - val_accuracy: 0.7917 - val_loss: 0.5889\n",
      "Epoch 10/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 185ms/step - accuracy: 0.9398 - loss: 0.1511 - val_accuracy: 0.8750 - val_loss: 0.3051\n",
      "Epoch 11/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 189ms/step - accuracy: 0.9451 - loss: 0.1371 - val_accuracy: 0.8429 - val_loss: 0.4477\n",
      "Epoch 12/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 190ms/step - accuracy: 0.9479 - loss: 0.1373 - val_accuracy: 0.7917 - val_loss: 0.6915\n",
      "Epoch 13/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 190ms/step - accuracy: 0.9465 - loss: 0.1439 - val_accuracy: 0.7901 - val_loss: 0.5817\n",
      "Epoch 14/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 182ms/step - accuracy: 0.9432 - loss: 0.1455 - val_accuracy: 0.8670 - val_loss: 0.4253\n",
      "Epoch 15/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 187ms/step - accuracy: 0.9544 - loss: 0.1161 - val_accuracy: 0.7901 - val_loss: 0.6934\n",
      "Epoch 16/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 192ms/step - accuracy: 0.9528 - loss: 0.1235 - val_accuracy: 0.8462 - val_loss: 0.4099\n",
      "Epoch 17/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 185ms/step - accuracy: 0.9536 - loss: 0.1236 - val_accuracy: 0.8221 - val_loss: 0.5771\n",
      "Epoch 18/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 192ms/step - accuracy: 0.9576 - loss: 0.1163 - val_accuracy: 0.7676 - val_loss: 0.6583\n",
      "Epoch 19/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 192ms/step - accuracy: 0.9575 - loss: 0.1114 - val_accuracy: 0.7949 - val_loss: 0.7066\n",
      "Epoch 20/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 185ms/step - accuracy: 0.9574 - loss: 0.1184 - val_accuracy: 0.8381 - val_loss: 0.4377\n",
      "Epoch 21/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 189ms/step - accuracy: 0.9584 - loss: 0.1070 - val_accuracy: 0.8269 - val_loss: 0.4731\n",
      "Epoch 22/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 191ms/step - accuracy: 0.9576 - loss: 0.1181 - val_accuracy: 0.7676 - val_loss: 0.6770\n",
      "Epoch 23/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 188ms/step - accuracy: 0.9584 - loss: 0.1097 - val_accuracy: 0.7804 - val_loss: 0.6080\n",
      "Epoch 24/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 182ms/step - accuracy: 0.9631 - loss: 0.1003 - val_accuracy: 0.8606 - val_loss: 0.4024\n",
      "Epoch 25/25\n",
      "\u001B[1m163/163\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 197ms/step - accuracy: 0.9597 - loss: 0.1066 - val_accuracy: 0.8125 - val_loss: 0.6366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1486820f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:21:46.879770Z",
     "start_time": "2025-02-09T02:21:46.838172Z"
    }
   },
   "cell_type": "code",
   "source": "cnn.save('pneumonia_detection-CNN.keras')",
   "id": "d84a2ec212599981",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 4 - Making a single prediction\n",
   "id": "50a53b4d5189dfb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T16:23:55.797488Z",
     "start_time": "2025-02-08T16:23:55.756749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img(\n",
    "    VALIDATION_SET_DIR + \"/PNEUMONIA/person1946_bacteria_4874.jpeg\",\n",
    "    target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'PNEUMONIA'\n",
    "else:\n",
    "    prediction = 'NORMAL'"
   ],
   "id": "6fefd23e4c2901f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T16:23:58.249577Z",
     "start_time": "2025-02-08T16:23:58.246031Z"
    }
   },
   "cell_type": "code",
   "source": "print(prediction)",
   "id": "4469f0fe6d6081ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNEUMONIA\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:29:56.573110Z",
     "start_time": "2025-02-09T02:29:56.479846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CATEGORIES = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def prepare(filepath):\n",
    "    test_image = image.load_img(filepath, target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    return  test_image\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('pneumonia_detection-CNN.keras')\n",
    "\n",
    "prediction = model.predict(prepare(TEST_SET_DIR + \"/NORMAL/IM-0015-0001.jpeg\"))\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ],
   "id": "d5f0c93adfbc8142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "[[0.]]\n",
      "NORMAL\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a08fce21bb91ed8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
