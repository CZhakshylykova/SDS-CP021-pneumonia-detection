{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chest X-ray Pneumonia Classification: End-to-End Notebook\n",
    "\n",
    "# ================================\n",
    "# 1. Imports & Setup\n",
    "# ================================\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, auc, f1_score\n",
    ")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n",
    "\n",
    "# Grad-CAM import (optional, will check availability later)\n",
    "try:\n",
    "    from pytorch_grad_cam import GradCAM\n",
    "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "    grad_cam_available = True\n",
    "except ImportError:\n",
    "    grad_cam_available = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. Set Seed for Reproducibility\n",
    "# ================================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. Config & Data Download\n",
    "# ================================\n",
    "dataset_dir = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "DATA_ROOT = os.path.join(dataset_dir, \"chest_xray\")\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "PATIENCE = 4\n",
    "IMG_SIZE = 128\n",
    "NUM_CLASSES = 2\n",
    "LOG_DIR = \"runs/chest_xray\"\n",
    "REPORTS_DIR = \"reports\"\n",
    "PLOTS_DIR = \"plots\"\n",
    "\n",
    "for folder in [REPORTS_DIR, PLOTS_DIR]:\n",
    "    os.makedirs(folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. Advanced Data Augmentation\n",
    "# ================================\n",
    "\n",
    "def to_1ch(x, **kwargs):\n",
    "    # If the image has shape (H, W, 3), pick the first channel only\n",
    "    if x.shape[-1] == 3:\n",
    "        x = x[..., 0:1]\n",
    "    return x\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, aug):\n",
    "        self.aug = aug\n",
    "    def __call__(self, img):\n",
    "        return self.aug(image=np.array(img))['image']\n",
    "\n",
    "train_aug = A.Compose([\n",
    "    A.ToGray(p=1.0),\n",
    "    A.Lambda(image=to_1ch),\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(p=0.5),\n",
    "        A.MotionBlur(p=0.5)\n",
    "    ], p=0.2),\n",
    "    A.Normalize([0.5], [0.5]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_aug = A.Compose([\n",
    "    A.ToGray(p=1.0),\n",
    "    A.Lambda(image=to_1ch),     # Fix for validation/test transforms!\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize([0.5], [0.5]),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. Dataset & Dataloaders (+Oversampling)\n",
    "# ================================\n",
    "class OversampledDataset(Dataset):\n",
    "    def __init__(self, normal_files, pneumonia_files, transform=None):\n",
    "        n_normal, n_pneumonia = len(normal_files), len(pneumonia_files)\n",
    "        if n_normal < n_pneumonia:\n",
    "            normal_files = normal_files * (n_pneumonia // n_normal) + random.sample(normal_files, n_pneumonia % n_normal)\n",
    "        elif n_pneumonia < n_normal:\n",
    "            pneumonia_files = pneumonia_files * (n_normal // n_pneumonia) + random.sample(pneumonia_files, n_normal % n_pneumonia)\n",
    "        self.images = normal_files + pneumonia_files\n",
    "        self.labels = [0]*len(normal_files) + [1]*len(pneumonia_files)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.images[idx]).convert('L')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "def get_dataloaders(data_root, batch_size=32):\n",
    "    train_normal = list((Path(data_root) / 'train' / 'NORMAL').glob('*.jpg')) + list((Path(data_root) / 'train' / 'NORMAL').glob('*.jpeg'))\n",
    "    train_pneu = list((Path(data_root) / 'train' / 'PNEUMONIA').glob('*.jpg')) + list((Path(data_root) / 'train' / 'PNEUMONIA').glob('*.jpeg'))\n",
    "\n",
    "    train_dataset = OversampledDataset(\n",
    "        [str(x) for x in train_normal],\n",
    "        [str(x) for x in train_pneu],\n",
    "        transform=AlbumentationsTransform(train_aug)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(Path(data_root) / 'val',\n",
    "                                      transform=AlbumentationsTransform(val_aug))\n",
    "    test_dataset = datasets.ImageFolder(Path(data_root) / 'test',\n",
    "                                       transform=AlbumentationsTransform(val_aug))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 6. Model (ResNet-18, 1-channel in)\n",
    "# ================================\n",
    "def get_model():\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 7. Training Loop, Early Stopping, Metrics\n",
    "# ================================\n",
    "def plot_metrics(train_hist, val_hist, name):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(train_hist, label='Train')\n",
    "    plt.plot(val_hist, label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    plt.legend()\n",
    "    plt.title(f'{name} curve')\n",
    "    plt.savefig(f\"{PLOTS_DIR}/{name.lower()}_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, epochs=10, patience=3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "    # Weighted loss for imbalance\n",
    "    class_counts = [0, 0]\n",
    "    for imgs, lbls in train_loader:\n",
    "        for l in lbls:\n",
    "            class_counts[l] += 1\n",
    "    weights = torch.FloatTensor([1/c if c>0 else 1 for c in class_counts]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    writer = SummaryWriter(LOG_DIR)\n",
    "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "    best_acc, patience_cnt = 0, 0\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), torch.tensor(labels).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            if scaler:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            train_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        avg_loss = train_loss / total\n",
    "        acc = correct / total\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accs.append(acc)\n",
    "        writer.add_scalar(\"Loss/Train\", avg_loss, epoch)\n",
    "        writer.add_scalar(\"Acc/Train\", acc, epoch)\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        all_val_preds, all_val_labels, all_val_probs = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                all_val_preds.extend(preds.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_probs.extend(probs[:,1].cpu().numpy())\n",
    "        val_acc = val_correct / val_total\n",
    "        avg_val_loss = val_loss / val_total\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        writer.add_scalar(\"Loss/Val\", avg_val_loss, epoch)\n",
    "        writer.add_scalar(\"Acc/Val\", val_acc, epoch)\n",
    "\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds)\n",
    "        val_auc = roc_auc_score(all_val_labels, all_val_probs)\n",
    "        writer.add_scalar(\"AUC/Val\", val_auc, epoch)\n",
    "        writer.add_scalar(\"F1/Val\", val_f1, epoch)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_loss:.4f}, Acc={acc:.4f} | Val Loss={avg_val_loss:.4f}, Acc={val_acc:.4f}, F1={val_f1:.4f}, AUC={val_auc:.4f}\")\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        # ---- EARLY STOPPING ----\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            patience_cnt = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    plot_metrics(train_losses, val_losses, \"Loss\")\n",
    "    plot_metrics(train_accs, val_accs, \"Accuracy\")\n",
    "    writer.close()\n",
    "    print(\"Best val accuracy: %.4f\" % best_acc)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 8. Evaluation: ROC, F1, Confusion Matrix, Report\n",
    "# ================================\n",
    "def plot_roc_curve(y_true, y_probs, filename):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {auc_val:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def eval_model(model, data_loader, device, split=\"Test\"):\n",
    "    model.eval()\n",
    "    test_correct, test_total = 0, 0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = outputs.argmax(1)\n",
    "            test_correct += (preds == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs[:,1].cpu().numpy())\n",
    "    acc = test_correct / test_total\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc_val = roc_auc_score(all_labels, all_probs)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cr = classification_report(all_labels, all_preds, target_names=['NORMAL', 'PNEUMONIA'])\n",
    "    plot_roc_curve(all_labels, all_probs, f\"{PLOTS_DIR}/roc_{split.lower()}.png\")\n",
    "    print(f\"{split} accuracy: {acc:.4f} | F1: {f1:.4f} | AUC: {auc_val:.4f}\")\n",
    "    print(f\"{split} Confusion matrix:\\n{cm}\")\n",
    "    print(f\"{split} Classification report:\\n{cr}\")\n",
    "    # Save report\n",
    "    with open(f\"{REPORTS_DIR}/{split.lower()}_report.txt\", \"w\") as f:\n",
    "        f.write(f\"{split} accuracy: {acc:.4f} | F1: {f1:.4f} | AUC: {auc_val:.4f}\\n\")\n",
    "        f.write(f\"{split} Confusion matrix:\\n{cm}\\n\")\n",
    "        f.write(f\"{split} Classification report:\\n{cr}\\n\")\n",
    "    return acc, f1, auc_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 9. Grad-CAM Visualizations (Optional, for Explainability)\n",
    "# ================================\n",
    "def gradcam_visualization(model, data_loader, device, out_dir):\n",
    "    if not grad_cam_available:\n",
    "        print(\"Grad-CAM is not installed. Skipping CAM visualizations.\")\n",
    "        return\n",
    "    model.eval()\n",
    "    target_layers = [model.layer4[-1]]\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=(device.type=='cuda'))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for batch_idx, (imgs, labels) in enumerate(data_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        grayscale_cam = cam(input_tensor=imgs, targets=None)\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i].detach().cpu().numpy().transpose(1,2,0)\n",
    "            img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "            cam_img = show_cam_on_image(img_norm, grayscale_cam[i], use_rgb=True)\n",
    "            plt.imsave(f\"{out_dir}/cam_{batch_idx}_{i}.png\", cam_img)\n",
    "        if batch_idx > 1:  # Only process a couple batches for demo\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 10. Main: Train, Evaluate, Explain\n",
    "# ================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, val_loader, test_loader = get_dataloaders(DATA_ROOT, batch_size=BATCH_SIZE)\n",
    "model = get_model().to(device)\n",
    "model = train_model(model, train_loader, val_loader, device, epochs=EPOCHS, patience=PATIENCE)\n",
    "# Load best model before test\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "print(\"\\n--- Validation Set Performance ---\")\n",
    "eval_model(model, val_loader, device, split=\"Validation\")\n",
    "print(\"\\n--- Test Set Performance ---\")\n",
    "eval_model(model, test_loader, device, split=\"Test\")\n",
    "# Grad-CAM visualizations\n",
    "if grad_cam_available:\n",
    "    gradcam_visualization(model, test_loader, device, out_dir=f\"{PLOTS_DIR}/gradcam\")\n",
    "print(\"\\nAll metrics, plots, and reports are saved in 'plots/' and 'reports/' folders. Check TensorBoard logs in 'runs/chest_xray'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
